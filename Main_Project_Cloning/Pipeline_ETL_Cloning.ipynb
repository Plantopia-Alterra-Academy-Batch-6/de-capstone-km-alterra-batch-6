{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "Forbidden",
     "evalue": "403 GET https://bigquery.googleapis.com/bigquery/v2/projects/plantopia-capstone/datasets/plantopia/tables/dim_plant_categories?prettyPrint=false: Access Denied: Table plantopia-capstone:plantopia.dim_plant_categories: Permission bigquery.tables.get denied on table plantopia-capstone:plantopia.dim_plant_categories (or it may not exist).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 225\u001b[0m\n\u001b[1;32m    211\u001b[0m table_functions \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim_plant_categories\u001b[39m\u001b[38;5;124m'\u001b[39m: insert_dim_plant_categories,\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim_plant_images\u001b[39m\u001b[38;5;124m'\u001b[39m: insert_dim_plant_images,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfact_watering_reminders\u001b[39m\u001b[38;5;124m'\u001b[39m: insert_fact_watering_reminders\n\u001b[1;32m    222\u001b[0m }\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m table, func \u001b[38;5;129;01min\u001b[39;00m table_functions\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 225\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Generate 100 records for each table\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData insertion and CSV creationÂ completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 47\u001b[0m, in \u001b[0;36minsert_dim_plant_categories\u001b[0;34m(num_records)\u001b[0m\n\u001b[1;32m     45\u001b[0m     data\u001b[38;5;241m.\u001b[39mappend(record)\n\u001b[1;32m     46\u001b[0m save_to_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim_plant_categories.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, data, data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m---> 47\u001b[0m \u001b[43mupload_to_bigquery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdim_plant_categories\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "Cell \u001b[0;32mIn[1], line 33\u001b[0m, in \u001b[0;36mupload_to_bigquery\u001b[0;34m(table_name, data)\u001b[0m\n\u001b[1;32m     31\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[1;32m     32\u001b[0m table_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 33\u001b[0m \u001b[43mto_gbq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreplace\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas_gbq/gbq.py:1155\u001b[0m, in \u001b[0;36mto_gbq\u001b[0;34m(dataframe, destination_table, project_id, chunksize, reauth, if_exists, auth_local_webserver, table_schema, location, progress_bar, credentials, api_method, verbose, private_key, auth_redirect_uri, client_id, client_secret)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     table_schema \u001b[38;5;241m=\u001b[39m pandas_gbq\u001b[38;5;241m.\u001b[39mschema\u001b[38;5;241m.\u001b[39mupdate_schema(\n\u001b[1;32m   1150\u001b[0m         default_schema, \u001b[38;5;28mdict\u001b[39m(fields\u001b[38;5;241m=\u001b[39mtable_schema)\n\u001b[1;32m   1151\u001b[0m     )\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;66;03m# Try to get the table\u001b[39;00m\n\u001b[0;32m-> 1155\u001b[0m     table \u001b[38;5;241m=\u001b[39m \u001b[43mbqclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination_table_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google_exceptions\u001b[38;5;241m.\u001b[39mNotFound:\n\u001b[1;32m   1157\u001b[0m     \u001b[38;5;66;03m# If the table doesn't already exist, create it\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m     table_connector \u001b[38;5;241m=\u001b[39m _Table(\n\u001b[1;32m   1159\u001b[0m         project_id_table,\n\u001b[1;32m   1160\u001b[0m         dataset_id,\n\u001b[1;32m   1161\u001b[0m         location\u001b[38;5;241m=\u001b[39mlocation,\n\u001b[1;32m   1162\u001b[0m         credentials\u001b[38;5;241m=\u001b[39mconnector\u001b[38;5;241m.\u001b[39mcredentials,\n\u001b[1;32m   1163\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/bigquery/client.py:1160\u001b[0m, in \u001b[0;36mClient.get_table\u001b[0;34m(self, table, retry, timeout)\u001b[0m\n\u001b[1;32m   1158\u001b[0m path \u001b[38;5;241m=\u001b[39m table_ref\u001b[38;5;241m.\u001b[39mpath\n\u001b[1;32m   1159\u001b[0m span_attributes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m: path}\n\u001b[0;32m-> 1160\u001b[0m api_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspan_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBigQuery.getTable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspan_attributes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspan_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Table\u001b[38;5;241m.\u001b[39mfrom_api_repr(api_response)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/bigquery/client.py:833\u001b[0m, in \u001b[0;36mClient._call_api\u001b[0;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    830\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m create_span(\n\u001b[1;32m    831\u001b[0m         name\u001b[38;5;241m=\u001b[39mspan_name, attributes\u001b[38;5;241m=\u001b[39mspan_attributes, client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, job_ref\u001b[38;5;241m=\u001b[39mjob_ref\n\u001b[1;32m    832\u001b[0m     ):\n\u001b[0;32m--> 833\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/cloud/_http/__init__.py:494\u001b[0m, in \u001b[0;36mJSONConnection.api_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    482\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    483\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    484\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m     extra_api_info\u001b[38;5;241m=\u001b[39mextra_api_info,\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_http_response(response)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expect_json \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[0;31mForbidden\u001b[0m: 403 GET https://bigquery.googleapis.com/bigquery/v2/projects/plantopia-capstone/datasets/plantopia/tables/dim_plant_categories?prettyPrint=false: Access Denied: Table plantopia-capstone:plantopia.dim_plant_categories: Permission bigquery.tables.get denied on table plantopia-capstone:plantopia.dim_plant_categories (or it may not exist)."
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from faker import Faker\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas_gbq import to_gbq\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "service_acc = os.getenv('SERVICE_ACCOUNT')\n",
    "project = os.getenv('PROJECT_ID')\n",
    "dataset = os.getenv('DATASET_ID')\n",
    "# Configure Google Cloud credentials and project details\n",
    "credentials = service_account.Credentials.from_service_account_file(service_acc)\n",
    "project_id = project\n",
    "dataset_id = dataset\n",
    "\n",
    "# Function to save data to CSV\n",
    "def save_to_csv(filename, data, headers):\n",
    "    with open(filename, 'w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=headers)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)\n",
    "\n",
    "# Function to upload data to BigQuery\n",
    "def upload_to_bigquery(table_name, data):\n",
    "    df = pd.DataFrame(data)\n",
    "    table_id = f\"{dataset_id}.{table_name}\"\n",
    "    to_gbq(df, table_id, project_id=project_id, if_exists='replace', credentials=credentials)\n",
    "\n",
    "# Function to generate dummy data for dim_plant_categories\n",
    "def insert_dim_plant_categories(num_records):\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        record = {\n",
    "            'plant_categories_id': fake.random_int(min=1, max=1000),\n",
    "            'name': fake.word(),\n",
    "            'created_at': fake.date_this_decade(),\n",
    "            'updated_at': fake.date_this_decade()\n",
    "        }\n",
    "        data.append(record)\n",
    "    save_to_csv('dim_plant_categories.csv', data, data[0].keys())\n",
    "    upload_to_bigquery('dim_plant_categories', data)\n",
    "    return data\n",
    "\n",
    "# Function to generate dummy data for dim_plant_images\n",
    "def insert_dim_plant_images(num_records):\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        record = {\n",
    "            'plant_images_id': fake.random_int(min=1, max=1000),\n",
    "            'src': fake.image_url(),\n",
    "            'created_at': fake.date_this_decade(),\n",
    "            'updated_at': fake.date_this_decade()\n",
    "        }\n",
    "        data.append(record)\n",
    "    save_to_csv('dim_plant_images.csv', data, data[0].keys())\n",
    "    upload_to_bigquery('dim_plant_images', data)\n",
    "    return data\n",
    "\n",
    "# Function to generate dummy data for dim_plant_instructions\n",
    "def insert_dim_plant_instructions(num_records):\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        record = {\n",
    "            'plant_instructions_id': fake.random_int(min=1, max=1000),\n",
    "            'step_number': fake.random_int(min=1, max=10),\n",
    "            'step_desc': fake.sentence(),\n",
    "            'step_image_url': fake.image_url(),\n",
    "            'additional_tips': fake.sentence(),\n",
    "            'created_at': fake.date_this_decade(),\n",
    "            'updated_at': fake.date_this_decade()\n",
    "        }\n",
    "        data.append(record)\n",
    "    save_to_csv('dim_plant_instructions.csv', data, data[0].keys())\n",
    "    upload_to_bigquery('dim_plant_instructions', data)\n",
    "    return data\n",
    "\n",
    "# Function to generate dummy data for dim_plant_characteristic\n",
    "def insert_dim_plant_characteristic(num_records):\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        record = {\n",
    "            'plant_characteristic_id': fake.random_int(min=1, max=1000),\n",
    "            'height': fake.random_int(min=10, max=200),\n",
    "            'height_unit': 'cm',\n",
    "            'wide': fake.random_int(min=10, max=200),\n",
    "            'wide_unit': 'cm',\n",
    "            'leaf_color': fake.color_name(),\n",
    "            'created_at': fake.date_this_decade(),\n",
    "            'updated_at': fake.date_this_decade()\n",
    "        }\n",
    "        data.append(record)\n",
    "    save_to_csv('dim_plant_characteristic.csv', data, data[0].keys())\n",
    "    upload_to_bigquery('dim_plant_characteristic', data)\n",
    "    return data\n",
    "\n",
    "# Function to generate dummy data for dim_plant_faqs\n",
    "def insert_dim_plant_faqs(num_records):\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        record = {\n",
    "            'plant_faqs_id': fake.random_int(min=1, max=1000),\n",
    "            'question': fake.sentence(),\n",
    "            'answer': fake.sentence(),\n",
    "            'created_at': fake.date_this_decade(),\n",
    "            'updated_at': fake.date_this_decade()\n",
    "        }\n",
    "        data.append(record)\n",
    "    save_to_csv('dim_plant_faqs.csv', data, data[0].keys())\n",
    "    upload_to_bigquery('dim_plant_faqs', data)\n",
    "    return data\n",
    "\n",
    "# Function to generate dummy data for dim_users\n",
    "def insert_dim_users(num_records):\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        record = {\n",
    "            'user_id': fake.random_int(min=1, max=1000),\n",
    "            'name': fake.name(),\n",
    "            'email': fake.email(),\n",
    "            'password': fake.password(),\n",
    "            'otp': fake.random_number(digits=6, fix_len=True),\n",
    "            'is_active': fake.boolean(),\n",
    "            'created_at': fake.date_this_decade(),\n",
    "            'updated_at': fake.date_this_decade()\n",
    "        }\n",
    "        data.append(record)\n",
    "    save_to_csv('dim_users.csv', data, data[0].keys())\n",
    "    upload_to_bigquery('dim_users', data)\n",
    "    return data\n",
    "\n",
    "# Function to generate dummy data for dim_plants\n",
    "def insert_dim_plants(num_records):\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        record = {\n",
    "            'plants_id': fake.random_int(min=1, max=1000),\n",
    "            'plant_images_id': fake.random_int(min=1, max=1000),\n",
    "            'name': fake.word(),\n",
    "            'description': fake.sentence(),\n",
    "            'is_toxic': fake.boolean(),\n",
    "            'harvest_duration': fake.random_int(min=1, max=365),\n",
    "            'plant_category_id': fake.random_int(min=1, max=1000),\n",
    "            'climates': fake.word(),\n",
    "            'created_at': fake.date_this_decade(),\n",
    "            'updated_at': fake.date_this_decade()\n",
    "        }\n",
    "        data.append(record)\n",
    "    save_to_csv('dim_plants.csv', data, data[0].keys())\n",
    "    upload_to_bigquery('dim_plants', data)\n",
    "    return data\n",
    "\n",
    "# Function to generate dummy data for fact_plants_data\n",
    "def insert_fact_plants_data(num_records):\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        record = {\n",
    "            'plant_categories_id': fake.random_int(min=1, max=1000),\n",
    "            'plant_faqs_id': fake.random_int(min=1, max=1000),\n",
    "            'plants_id': fake.random_int(min=1, max=1000),\n",
    "            'user_id': fake.random_int(min=1, max=1000),\n",
    "            'plant_characteristic_id': fake.random_int(min=1, max=1000),\n",
    "            'plant_instructions_id': fake.random_int(min=1, max=1000),\n",
    "            'total_plants': fake.random_int(min=1, max=100),\n",
    "            'plants_by_category': fake.random_int(min=1, max=100)\n",
    "        }\n",
    "        data.append(record)\n",
    "    save_to_csv('fact_plants_data.csv', data, data[0].keys())\n",
    "    upload_to_bigquery('fact_plants_data', data)\n",
    "    return data\n",
    "\n",
    "# Function to generate dummy data for fact_fertilizer\n",
    "def insert_fact_fertilizer(num_records):\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        record = {\n",
    "            'user_id': fake.random_int(min=1, max=1000),\n",
    "            'plants_id': fake.random_int(min=1, max=1000),\n",
    "            'plant_categories_id': fake.random_int(min=1, max=1000),\n",
    "            'fertilizer_amount': fake.random_int(min=1, max=100),\n",
    "            'fertilizer_frequency': fake.random_int(min=1, max=365)\n",
    "        }\n",
    "        data.append(record)\n",
    "    save_to_csv('fact_fertilizer.csv', data, data[0].keys())\n",
    "    upload_to_bigquery('fact_fertilizer', data)\n",
    "    return data\n",
    "\n",
    "# Function to generate dummy data for fact_watering_reminders\n",
    "def insert_fact_watering_reminders(num_records):\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        record = {\n",
    "            'user_id': fake.random_int(min=1, \n",
    "                                       max=1000),\n",
    "            'plants_id': fake.random_int(min=1, max=1000),\n",
    "            'plant_categories_id': fake.random_int(min=1, max=1000),\n",
    "            'watering_frequency': fake.random_int(min=1, max=365),\n",
    "            'watering_amount': fake.random_int(min=1, max=100)\n",
    "        }\n",
    "        data.append(record)\n",
    "    save_to_csv('fact_watering_reminders.csv', data, data[0].keys())\n",
    "    upload_to_bigquery('fact_watering_reminders', data)\n",
    "    return data\n",
    "\n",
    "# Generate and insert dummy data\n",
    "table_functions = {\n",
    "    'dim_plant_categories': insert_dim_plant_categories,\n",
    "    'dim_plant_images': insert_dim_plant_images,\n",
    "    'dim_plant_instructions': insert_dim_plant_instructions,\n",
    "    'dim_plant_characteristic': insert_dim_plant_characteristic,\n",
    "    'dim_plant_faqs': insert_dim_plant_faqs,\n",
    "    'dim_users': insert_dim_users,\n",
    "    'dim_plants': insert_dim_plants,\n",
    "    'fact_plants_data': insert_fact_plants_data,\n",
    "    'fact_fertilizer': insert_fact_fertilizer,\n",
    "    'fact_watering_reminders': insert_fact_watering_reminders\n",
    "}\n",
    "\n",
    "for table, func in table_functions.items():\n",
    "    data = func(100)  # Generate 100 records for each table\n",
    "\n",
    "print(\"Data insertion and CSV creationÂ completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
